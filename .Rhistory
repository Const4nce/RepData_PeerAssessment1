library(RMySQL)
ucscDb <- dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb, "show databases;"); dbDisconnect(ucscDb)
result
hg19 <- dbConnect(MySQL(), user = "genome", db = "hg19", host = "genome-mysql.cse.ucsc.edu") # the difference here is that we specify a database (the hg19)
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
dbListFields(hg19,"affyU133Plus2")
dbListFields(hg19,"affyU133Plus2") # the one in brackets is the table of interest, with this we
#already know about the columns
dbGetQuery(hg19, "select count (*) from affyU133Plus2") #with this we can get info about rows
dbListFields(hg19,"affyU133Plus2") # the one in brackets is the table of interest, with this we
#already know about the columns
dbGetQuery(hg19, "select count(*) from affyU133Plus2") #with this we can get info about rows
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis <- fetch(query); quantile(affyMis$misMatches)
affyMisSmall <- fetch(query, n = 10); dbClearResult(query);
dim(affymisSmall)
dim(affyMisSmall)
dbDisconnect(hg19)
install.packages("sqldf")
library(sqldf)
acs <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", header = TRUE)
sqldf("select pwgtp1 from acs where AGEP < 50")
library(data.table, sqldf)
acs_dt <- read.table(acs)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
acs <- read.table(read.csv(url))
f <- file.path(getwd(), "ss06pid.csv")
download.file(url, f)
acs <- data.table(read.csv(f))
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
son1 <- content(homeTL) #using content function we extract the json data
json2 <- jsonlite::fromJSON(toJSON(json1)) #json data as extracted before are hard to read
### so we use the jsonlite packages to simplify the data into a readable format
json2[1,1:4]
json1 <- content(homeTL) #using content function we extract the json data
json2 <- jsonlite::fromJSON(toJSON(json1)) #json data as extracted before are hard to read
### so we use the jsonlite packages to simplify the data into a readable format
json2[1,1:4]
json2 <- jsonlite::fromJSON(toJSON(json1))
install.packages("jsonlite")
install.packages("jsonlite")
json2 <- jsonlite::fromJSON(toJSON(json1))
library(jsonlite)
load(jsonlite)
library(jsonlite)
install.packages("jsonlite")
install.packages("jsonlite")
library(jsonlite)
json2 <- jsonlite::fromJSON(toJSON(json1))
json1 <- content(homeTL) #using content function we extract the json data
json2 <- jsonlite::fromJSON(toJSON(json1))
json1 <- content(homeTL)
library(sqldf)
json1 <- content(homeTL)
library(json)
library(RMySQL)
json1 <- content(homeTL)
library(jsonlite)
json1 <- content(homeTL)
myapp <- oauth_app("twitter", key = "myconsumerkeyhereasgotfromtwitterdeveloperaccount", secret = "myconsumersecrethere") ###
### starts the authorization process, we name the application, whatever we want - twitter for convenience since we are
### working with twitter data here
sig = sign_oauth1.0(myapp, token = "mytokenhere", token_secret = "mytokensecrethere")
### here we take the application we authorized before and we sign in using our token as
### provided by twitter (collect these info from the website)
homeTL <- GET("http://api,twitter.com/1.1/statuses/home_timeline.json", sig)
library(RMySQL)
lirari(DBI)
library(DBI)
library(RMySQL)
myapp <- oauth_app("twitter", key = "myconsumerkeyhereasgotfromtwitterdeveloperaccount", secret = "myconsumersecrethere") ###
### starts the authorization process, we name the application, whatever we want - twitter for convenience since we are
### working with twitter data here
sig = sign_oauth1.0(myapp, token = "mytokenhere", token_secret = "mytokensecrethere")
### here we take the application we authorized before and we sign in using our token as
### provided by twitter (collect these info from the website)
homeTL <- GET("http://api,twitter.com/1.1/statuses/home_timeline.json", sig)
myapp <- oauth_app("twitter", key = "myconsumerkeyhereasgotfromtwitterdeveloperaccount", secret = "myconsumersecrethere") ###
### starts the authorization process, we name the application, whatever we want - twitter for convenience since we are
### working with twitter data here
myapp <- oauth_app("twitter", key = "myconsumerkeyhereasgotfromtwitterdeveloperaccount", secret = "myconsumersecrethere") ###
### starts the authorization process, we name the application, whatever we want - twitter for convenience since we are
### working with twitter data here
sig = sign_oauth1.0(myapp, token = "mytokenhere", token_secret = "mytokensecrethere")
library(RMySQL)
sig = sign_oauth1.0(myapp, token = "mytokenhere", token_secret = "mytokensecrethere")
install.packages("httr")
install.packages("httpuv")
library(httr)
require(httpuv)
require(jsonlite)
myapp <- oauth_app("twitter", key = "myconsumerkeyhereasgotfromtwitterdeveloperaccount", secret = "myconsumersecrethere") ###
### starts the authorization process, we name the application, whatever we want - twitter for convenience since we are
### working with twitter data here
sig = sign_oauth1.0(myapp, token = "mytokenhere", token_secret = "mytokensecrethere")
sig = sign_oauth1.0(myapp, token = "mytokenhere", token_secret = "mytokensecrethere")
homeTL <- GET("http://api,twitter.com/1.1/statuses/home_timeline.json", sig)
### here we use the get function, and we specify the twitter url that contains t
homeTL <- GET("http://api,twitter.com/1.1/statuses/home_timeline.json", sig)
require(dplyr)
homeTL <- GET("http://api,twitter.com/1.1/statuses/home_timeline.json", sig)
install.packages("base64enc")
homeTL <- GET("http://api,twitter.com/1.1/statuses/home_timeline.json", sig)
library(httr)
require(httpuv)
require(jsonlite)
require(dplyr)
myapp <- oauth_app("twitter", key = "myconsumerkeyhereasgotfromtwitterdeveloperaccount", secret = "myconsumersecrethere") ###
sig = sign_oauth1.0(myapp, token = "mytokenhere", token_secret = "mytokensecrethere")
homeTL <- GET("http://api,twitter.com/1.1/statuses/home_timeline.json", sig)
homeTL <- GET("http://api.twitter.com/1.1/statuses/home_timeline.json", sig)
json1 <- content(homeTL)
library(jsonlite)
json2 <- jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
json2 <- jsonlite::fromJSON(toJSON(json1))
json2 <- jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
myapp <- oauth_app("twitter", key = "MNaOPIEaQm5usCuEwNjFlmH2X", secret = "yMId4zVXrsUygPGPtZR6eFO3KhRNGVawD47O6D4GVLwi3EHAlD") ###
### starts the authorization process, we name the application, whatever we want - twitter for convenience since we are
sig = sign_oauth1.0(myapp, token = "154964285-0KFFdEzIa3HTEI9dzQTOfd1PhtcCcjS56t6k7TWW", token_secret = "bU4jlbxGZWB89M6OmJADZcfxn3UsB3HFcylQkCOzDuX70")
### here we take the application we authorized before and we sign in using our token as
### provided by twitter (collect these info from the website)
homeTL <- GET("http://api.twitter.com/1.1/statuses/home_timeline.json", sig)
json1 <- content(homeTL)
library(jsonlite)
json2 <- jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
homeTL <- GET("http://api.twitter.com/1.1/statuses/home_timeline.json", sig)
library(jsonlite)
json2 <- jsonlite::fromJSON(toJSON(json1)) #
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "ffc706c9a4c2d882e0ea",
secret = "9bdf26fee6ac8b33237a4a88a3b9ddc5dea0d2b4")
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "ffc706c9a4c2d882e0ea",
secret = "9bdf26fee6ac8b33237a4a88a3b9ddc5dea0d2b4")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
req <- with_config(gtoken, GET("https://api.github.com/rate_limit"))
stop_for_status(req)
content(req)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1))
head(json2)
json2[json2$full_name == "jtleek/datasharing",]
con <- url("https://scholar.google.com/citations?user=HI-I6C0AAAAJ")
htmlCode <- readLines(con)
close(con)
htmlCode
install.packages("XML")
library(XML)
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
xpathSApply(html, "//title",xmlValue)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
xpathSApply(html, "//title",xmlValue)
xpathSapply(html, "//td[@id = 'col-citedby']", xmlValue)
xpathSApply(html, "//td[@id = 'col-citedby']", xmlValue)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
xpathSApply(html, "//td[@id = 'col-citedby']", xmlValue)
html <- htmlTreeParse(url, useInternalNodes = TRUE)
htm
html
xpathSApply(html, "//title",xmlValue)
xpathSApply(html, "//td[@id = 'col-citedby']", xmlValue)
xpathSApply(html, "//td[@id = "col-citedby"]", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
xpathSApply(html,"//td[@class='gsc_a_c']",xmlValue)
library(RCurl)
library(XML)
library(httr)
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml = htmlParse(content2, asText = TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)
pg2 <- GET("http://httpbin.org/basic-auth/user/passwd", authenticate("user", "passwd"))
pg2
names(pg2)
google = handle("http://google.com")
pg1 = GET(handle = google, path = "/")
pg2 = GET(handle = google, path = "search")
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(con)
close(con) #make sure to close the connection after using it
htmlCode
library(XML)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html <- htmlTreeParse(url, useInternalNodes = TRUE) #useInternalNodes to get the complete structure out
x<- nchar[10,20,30,100]
?nchar
x<- c(nchar(html[10]), nchar(html[20]), nchar(html[30]), nchar(html[100]))
x<- c(nchar(htmlCode[10]), nchar(htmlCode[20]), nchar(htmlCode[30]), nchar(htmlCode[100]))
x
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
lines
?read.fwf
read.fwf(url, skip = 4)
cat(">",paste0(rep(c(1:9,"+"),6),collapse=""))
lines
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
d <- read.fwf(url, w, header=FALSE, skip=4, col.names=colNames)
d <- d[, grep("^[^filler]", names(d))]
sum(d[, 4])
read.fwf(url,widths = c(15, 4, 1, 3, 5, 4) skip = 4)
read.fwf(url,widths = c(15, 4, 1, 3, 5, 4), skip = 4)
lines
q <- read.fwf(url,widths = c(15, 4, 1, 3, 5, 4), skip = 4)
q
q <- read.fwf(url,widths = c(14, 5, 1, 3, 5, 4), skip = 4)
q
q <- read.fwf(url,widths = c(15, 4, 1, 3, 5, 4), skip = 4)
q
sum(q$V6)
q <- read.fwf(url,widths = c(9, 4, 1, 3, 5, 4), skip = 4)
q
q <- read.fwf(url,widths = c(10, 4, 1, 3, 5, 4), skip = 4)
q
q <- read.fwf(url,widths = c(15, 4, 1, 3, 3, 4), skip = 4)
q
q <- read.fwf(url,widths = c(15, 4, 1, 3, 5, 4), skip = 4)
q
lines
lines <- readLines(url)
lines
q
lines
q
q <- read.fwf(url,widths = c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3), skip = 4)
q
q <- read.fwf(url,widths = c(15, 4, 1, 3, 5, 4), skip = 4)
sum(q$V6)
q <- read.fwf(url,widths = c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3), skip = 4)
colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
d <- read.fwf(url, w, header=FALSE, skip=4, col.names=colNames)
d <- d[, grep("^[^filler]", names(d))]
sum(d[, 4])
d <- d[, grep("^[^filler]", names(d))]
d
install.packages("lattice")
library(lattice)
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("ggplot2")
library(ggplot2)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
g <- ggplot(movies, aes(votes, rating))
print(g)
data(movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
install.packages("knitr")
library(knitr)
install.packages("knitr")
library(knitr)
install.packages("slidify")
```{r}
summary(cars)
```
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("stats")
ap <- available.packages()
ap
?available.packages
options(install.packages.check.source = "no")
install.packages("stats")
install.packages("stats")
options(install.packages.check.source = "yes")
install.packages("stats")
install.packages("stats")
install.packages("stats")
avg_interval <- mean(total_steps$interval)
avg_interval <- aggregate(steps ~ interval, activity_data, mean, na.rm = TRUE)
activity_data <- read.csv("activity.csv")
directory <- "C:\\Users\\Constantina\\Google Drive\\coursera\\Reproducible Research\\"
setwd(directory)
#get directory
getwd()
#read data and check class(we want df for markdowns)
activity_data <- read.csv("activity.csv")
avg_interval <- aggregate(steps ~ interval, activity_data, mean, na.rm = TRUE)
head(avg_interval)
plot(avg_interval$interval, avg_interval$steps, main = "Average number of steps by interval" xlab = "Time interval", ylab = "Steps")
plot(avg_interval$interval, avg_interval$steps, main = "Average number of steps by interval", xlab = "Time interval", ylab = "Steps")
plot(avg_interval$interval, avg_interval$steps, type = "l", main = "Average number of steps by interval", xlab = "Time interval", ylab = "Steps")
max_steps <- max(avg_interval)
max_steps <- avg_interval[which.max(avg_interval$interval)]
max_steps <- avg_interval[which.max(avg_interval$steps)]
str(avg_interval)
max_steps <- avg_interval$interval[which.max(avg_interval$steps)]
max_steps
max_steps <- which.max(avg_interval$steps)
max_steps
activity_data[is.na]
is.na(activity_data)
sum(is.na(activity_data))
for(i in 1:length(activity_data)){
if(is.na(activity_data$steps[i])){
activity_data$steps[i] <- mean(activity_data$steps[interval])
}
}
for(i in 1:length(activity_data$interval)){
if(is.na(activity_data$steps[i])){
new_value <- mean(activity_data$steps[activity_data$interval]
}
}
for(i in 1:length(activity_data$interval)){
if(is.na(activity_data$steps[i])){
new_value <- mean(activity_data$steps[activity_data$interval])
}
}
for(i in 1:length(activity_data$interval)){
if(is.na(activity_data$steps[i])){
new_value <- mean(activity_data$interval[activity_data$steps])
}
}
for(i in nrow(activity_data$interval)){
if(is.na(activity_data$steps[i])){
new_value <- mean(activity_data$interval[activity_data$steps])
}
}
for(i in nrow(activity_data$interval)){
if(is.na(activity_data$steps[i])){
new_value <- tapply(activityData$steps, activityData$interval, mean)
}
}
for(i in nrow(activity_data$interval)){
if(is.na(activity_data$steps[i])){
new_value <- tapply(activityData$steps, activityData$interval, mean)
}
}
new_value
for(i in nrow(activity_data$interval)){
if(is.na(activity_data$steps[i])){
new_value <- tapply(activityData$steps, activityData$interval, mean)
activity_data$steps[i] <- new_value
}
}
head(activity_data)
?mean
for(i in nrow(activity_data$interval)){
if(is.na(activity_data$steps[i])){
new_value <- mean(activity_data$steps[which(activity_data$interval)])
activity_data$steps[i] <- new_value
}
}
head(activity_data)
for(i in nrow(activity_data$interval)){
if(is.na(activity_data$steps[i])){
new_value <- mean(activity_data$steps[which(avg_interval$interval == activity_data$interval[i])])
activity_data$steps[i] <- new_value
}
}
head(activity_data)
for(i in nrow(activity_data$interval)){
if(is.na(activity_data$steps[i])){
new_value <- aggregate(steps ~ interval, activity_data, mean)
#activity_data$steps[which(avg_interval$interval == activity_data$interval[i])])
activity_data$steps[i] <- new_value
}
}
head(activity_data)
num_of_steps <- avg_interval[max_steps,]
num_of_steps
new_dataset <- activity_data
for(i in nrow(new_dataset$interval)){
if(is.na(new_dataset$steps[i])){
interval_value <- new_dataset$interval[i]
step_value <- avg_interval[avg_interval$interval == inteval_value, ]
new_dataset$steps[i] <- step_value$steps
}
}
head(new_dataset)
new_dataset <- activity_data
for(i in 1:nrow(new_dataset$interval)){
if(is.na(new_dataset$steps[i])){
interval_value <- new_dataset$interval[i]
step_value <- avg_interval[avg_interval$interval == inteval_value, ]
new_dataset$steps[i] <- step_value$steps
}
}
new_dataset <- activity_data
for(i in 1:nrow(new_dataset)){
if(is.na(new_dataset$steps[i])){
interval_value <- new_dataset$interval[i]
step_value <- avg_interval[avg_interval$interval == inteval_value, ]
new_dataset$steps[i] <- step_value$steps
}
}
new_dataset <- activity_data
for(i in 1:nrow(new_dataset)){
if(is.na(new_dataset$steps[i])){
interval_value <- new_dataset$interval[i]
step_value <- avg_interval[avg_interval$interval == interval_value, ]
new_dataset$steps[i] <- step_value$steps
}
}
head(new_dataset)
sum(is.na(new_dataset))
sum(is.na(new_dataset$steps))
avg_interval
str(new_step_value)
?hist
hist(new_dataset$steps, main = "Number of steps per day with NA removed", xlab = "Steps", ylab = "Frequency")
?weekdays
new_dataset$day <- weekdays(new_dataset$date)
imp <- new_dataset
imp$day <- weekdays(imp$date)
imp$week <- ""
imp[imp$day == "Saturday" | imp$day == "Sunday", ]$week <- "weekend"
imp[!(imp$day == "Saturday" | imp$day == "Sunday"), ]$week <- "weekday"
imp$week <- factor(imp$week)
new_dataset["day"] <- weekdays(new_dataset$date)
new_dataset["day"] <- NA
str(new_dataset)
week_day <- function(date_val) {
wd <- weekdays(as.Date(date_val, '%Y-%m-%d'))
if  (!(wd == 'Saturday' || wd == 'Sunday')) {
x <- 'Weekday'
} else {
x <- 'Weekend'
}
x
}
new_dataset$day <- NA
head(activity_data)
new_dataset$day <- NA
day <- weekdays(as.Date(new_dataset$date, format = "%Y-%m-%d"))
for (i in 1:nrow(day)){
if (day[i] == "Saturday" | day[i] == "Sunday"){
new_dataset$day[i] <- "Weekend"
} else {
new_dataset$day[i] <- "Weekday"
}
}
head(activity_data)
new_dataset$day <- NA
day <- weekdays(as.Date(new_dataset$date, format = "%Y-%m-%d"))
for (i in 1:nrow(new_dataset)){
if (day[i] == "Saturday" | day[i] == "Sunday"){
new_dataset$day[i] <- "Weekend"
} else {
new_dataset$day[i] <- "Weekday"
}
}
head(new_dataset)
tail(new_dataset)
str(new_dataset)
new_dataset
new_dataset["Weekend" %in% new_dataset$day]
class(new_dataset$date)
day
avg_step_int_day <- aggregate(steps ~ interval + day, data = new_dataset, mean)
library(lattice)
xyplot(steps ~ interval | week, data = new_dataset, type = "l", lwd = 2, layout = c(1,2), main = "Average number of steps across weekend and weekdays", xlab = "5-minute interval", ylab = "Average number of steps")
xyplot(steps ~ interval | day, data = new_dataset, type = "l", lwd = 2, layout = c(1,2), main = "Average number of steps across weekend and weekdays", xlab = "5-minute interval", ylab = "Average number of steps")
xyplot(steps ~ interval | day, data = new_dataset, type = "l", lwd = 2, layout = c(1,2), main = "Average number of steps across weekend and weekdays", xlab = "5-minute interval", ylab = "Average number of steps")
xyplot(steps ~ interval | day, data = new_dataset, type = "l", lwd = 1, layout = c(1,2), main = "Average number of steps across weekend and weekdays", xlab = "5-minute interval", ylab = "Average number of steps")
xyplot(steps ~ interval | day, data = total_steps, type = "l", lwd = 1, layout = c(1,2), main = "Average number of steps across weekend and weekdays", xlab = "5-minute interval", ylab = "Average number of steps")
xyplot(steps ~ interval | day, data = avg_step_int_day, type = "l", lwd = 2, layout = c(1,2), main = "Average number of steps across weekend and weekdays", xlab = "5-minute interval", ylab = "Average number of steps")
xyplot(steps ~ interval | day, data = avg_step_int_day, type = "l", lwd = 1, layout = c(1,2), main = "Average number of steps across weekend and weekdays", xlab = "5-minute interval", ylab = "Average number of steps")
interpret(new_dataset)
view(dataset)
print(new_dataset, quote = TRUE, row.names = FALSE)
glimpse(new_dataset)
library(dplyr)
glimpse(new_dataset)
summary(new_dataset)
str(new_dataset)
str(new_dataset$day)
summary(new_dataset$day)
glimpse(new_dataset$day)
